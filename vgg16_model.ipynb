{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXaoVO+QhB6WCFdbiYak9P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Sunmoon2021/ImageProcessingProjects/blob/main/vgg16_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_x76V39YqjG"
      },
      "source": [
        "#モジュールオブジェクトのインポート\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Dropout, Flatten, Input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model, Sequential\n",
        "from keras import optimizers\n",
        "from os import listdir\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Yh-ehVYsyR",
        "outputId": "095ee263-9a6b-44c8-beaf-486c652345bd"
      },
      "source": [
        "\n",
        "#イメージサイズの定義をする\n",
        "image_size = 50\n",
        "\n",
        "#listdir('./xx/')ファイルの中にある画像を入れる。\n",
        "path_bh = [filename for filename in listdir('/content/meats/rare/') if not filename.startswith('.')]\n",
        "path_bu = [filename for filename in listdir('/content/meats/welldone/') if not filename.startswith('.')]\n",
        "path_rollar = [filename for filename in listdir('/content/meats/test/') if not filename.startswith('.')]\n",
        "\n",
        "\n",
        "\n",
        "#各ファイルを順番に呼び出す。（ファイルにある個数分繰り返す。）\n",
        "#OpenCVで画像サイズをリサイズして統一する。\n",
        "#img_にリサイズしたものを加える。\n",
        "\n",
        "img_bh = []\n",
        "img_bu = []\n",
        "img_rollar = []\n",
        "for i in range(len(path_bh)):\n",
        "   img = cv2.imread('/content/meats/rare/'+ path_bh[i])\n",
        "   img = cv2.resize(img,(image_size,image_size))\n",
        "   img_bh.append(img)\n",
        "for i in range(len(path_bu)):\n",
        "   img = cv2.imread('/content/meats/welldone/'+ path_bu[i])\n",
        "   img = cv2.resize(img,(image_size,image_size))\n",
        "   img_bu.append(img)\n",
        "for i in range(len(path_rollar)):\n",
        "   img = cv2.imread('/content/meats/test/'+ path_rollar[i])\n",
        "   img = cv2.resize(img,(image_size,image_size))\n",
        "   img_rollar.append(img)\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(img_bh + img_bu + img_rollar) #行列をくっつける。\n",
        "y = np.array([0]*len(img_bh) + [1]*len(img_bu) + [2]*len(img_rollar)) #０、１、２と種類ごとに番号をつける。\n",
        "rand_index = np.random.permutation(np.arange(len(X))) #np.arange(x)の配列をランダムに並べ替えてrand_indexに入れる。\n",
        "X = X[rand_index] #Xをrand_index順に並び替える\n",
        "y = y[rand_index] #yをrand_index順に並び替える\n",
        "\n",
        "#データを分割する。\n",
        "X_train = X[:int(len(X)*0.8)] #トレーニングデータ８割未満\n",
        "y_train = y[:int(len(y)*0.8)]\n",
        "X_test = X[int(len(X)*0.8):] #トレーニングデータ以外\n",
        "y_test = y[int(len(y)*0.8):]\n",
        "\n",
        "#各属性を表示する。\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "y_train = to_categorical(y_train) #One-Hotベクトルを作成する。\n",
        "y_test = to_categorical(y_test) #One-Hotベクトルを作成する。\n",
        "\n",
        "# 転移学習（VGG16モデル)を活用する。ImageNetで事前学習した重みを読み込む。\n",
        "input_tensor = Input(shape=(image_size, image_size, 3)) \n",
        "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "\n",
        "#特徴抽出部分以降に新しく他の層を追加するにために、あらかじめVGGとは別のモデル（ここではtop_model）を定義する。\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=vgg16.output_shape[1:])) #VGGを結合する。\n",
        "\n",
        "top_model.add(Dense(256, activation=\"sigmoid\")) #1つ目の全結合層の出力ユニット数は256,活性化関数はshigmoid.\n",
        "top_model.add(Dropout(0.5))                     #過学習を防ぐ。\n",
        "top_model.add(Dense(64, activation='sigmoid'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(32, activation='sigmoid'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(3, activation='softmax')) #ソフトマックス関数を用いて3次元で出力する。\n",
        "\n",
        "## vgg16とtop_modelを連結してください\n",
        "model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n",
        "\n",
        "#15番目の層までは固定し、それ以降のものを繰り返し学習する。\n",
        "for layer in model.layers[:15]:\n",
        "   layer.trainable = False\n",
        "\n",
        "#コンパイルする。\n",
        "model.compile(loss='categorical_crossentropy', #多クラス分類の損失関数を定義する。\n",
        "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), #最適化関数を定義する。\n",
        "             metrics=['accuracy']) #評価関数を定義する。\n",
        "\n",
        "#X_train, y_trainを用いて学習を行う。テストデータは、X_test, y_test。\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=25, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "#精度の評価する。\n",
        "score = model.evaluate(X_test, y_test, batch_size=32, verbose=0)\n",
        "print('validation loss:{0[0]}\\nvalidation accuracy:{0[1]}'.format(score))\n",
        "\n",
        "#モデルを保存する。\n",
        "model.save(\"my_model.h5\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(376, 50, 50, 3)\n",
            "(376,)\n",
            "(94, 50, 50, 3)\n",
            "(94,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.2744 - accuracy: 0.3401 - val_loss: 1.0803 - val_accuracy: 0.4362\n",
            "Epoch 2/25\n",
            "12/12 [==============================] - 17s 1s/step - loss: 1.2616 - accuracy: 0.3331 - val_loss: 1.0723 - val_accuracy: 0.4362\n",
            "Epoch 3/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.2000 - accuracy: 0.3812 - val_loss: 1.0637 - val_accuracy: 0.4362\n",
            "Epoch 4/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1238 - accuracy: 0.4172 - val_loss: 1.0556 - val_accuracy: 0.4362\n",
            "Epoch 5/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.2489 - accuracy: 0.3835 - val_loss: 1.0482 - val_accuracy: 0.4362\n",
            "Epoch 6/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1554 - accuracy: 0.4380 - val_loss: 1.0413 - val_accuracy: 0.4362\n",
            "Epoch 7/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.2314 - accuracy: 0.3336 - val_loss: 1.0347 - val_accuracy: 0.4362\n",
            "Epoch 8/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.0715 - accuracy: 0.4609 - val_loss: 1.0287 - val_accuracy: 0.4362\n",
            "Epoch 9/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1429 - accuracy: 0.4196 - val_loss: 1.0238 - val_accuracy: 0.4362\n",
            "Epoch 10/25\n",
            "12/12 [==============================] - 17s 1s/step - loss: 1.1239 - accuracy: 0.3936 - val_loss: 1.0185 - val_accuracy: 0.4362\n",
            "Epoch 11/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1986 - accuracy: 0.3754 - val_loss: 1.0133 - val_accuracy: 0.4362\n",
            "Epoch 12/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1166 - accuracy: 0.4419 - val_loss: 1.0083 - val_accuracy: 0.4362\n",
            "Epoch 13/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1417 - accuracy: 0.4151 - val_loss: 1.0038 - val_accuracy: 0.4362\n",
            "Epoch 14/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1300 - accuracy: 0.4144 - val_loss: 0.9995 - val_accuracy: 0.4362\n",
            "Epoch 15/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1524 - accuracy: 0.3976 - val_loss: 0.9954 - val_accuracy: 0.4362\n",
            "Epoch 16/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1129 - accuracy: 0.4257 - val_loss: 0.9920 - val_accuracy: 0.4362\n",
            "Epoch 17/25\n",
            "12/12 [==============================] - 17s 1s/step - loss: 1.1827 - accuracy: 0.3848 - val_loss: 0.9891 - val_accuracy: 0.4362\n",
            "Epoch 18/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1175 - accuracy: 0.4049 - val_loss: 0.9861 - val_accuracy: 0.4362\n",
            "Epoch 19/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.0759 - accuracy: 0.4486 - val_loss: 0.9833 - val_accuracy: 0.4362\n",
            "Epoch 20/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1230 - accuracy: 0.4643 - val_loss: 0.9803 - val_accuracy: 0.4468\n",
            "Epoch 21/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1725 - accuracy: 0.3930 - val_loss: 0.9778 - val_accuracy: 0.4468\n",
            "Epoch 22/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.0941 - accuracy: 0.3832 - val_loss: 0.9752 - val_accuracy: 0.4574\n",
            "Epoch 23/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.0934 - accuracy: 0.4398 - val_loss: 0.9730 - val_accuracy: 0.4574\n",
            "Epoch 24/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.0592 - accuracy: 0.4683 - val_loss: 0.9709 - val_accuracy: 0.4574\n",
            "Epoch 25/25\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1403 - accuracy: 0.4302 - val_loss: 0.9690 - val_accuracy: 0.4574\n",
            "validation loss:0.9690297842025757\n",
            "validation accuracy:0.457446813583374\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}